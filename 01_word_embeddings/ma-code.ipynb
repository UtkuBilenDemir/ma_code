{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "from scipy.spatial import distance\n",
    "model = gensim.downloader.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c96a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10212945938110352\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(\n",
    "    distance.cosine(model[\"queen\"], model[\"king\"]) - distance.cosine(model[\"woman\"], model[\"man\"]),\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b126eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The (cosine) distance between (king - man + woman) and queen is 0.13904184103012085\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dis = distance.cosine((model[\"king\"]  - model[\"man\"] + model[\"woman\"]), model[\"queen\"])\n",
    "print(f\"The (cosine) distance between (king - man + woman) and queen is {dis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5962bf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.096574380993843\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distance.cosine(model[\"bank\"], model[\"bunny\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308bcc94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6826266348361969\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "distance.cosine(model[\"football\"], model[\"female\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1921b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim numpy scipy scikit-learn\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import gensim.downloader as api\n",
    "\n",
    "\n",
    "def v(w):\n",
    "    \"\"\"Vector for word w, with a helpful error if missing.\"\"\"\n",
    "    try:\n",
    "        return model[w]\n",
    "    except KeyError:\n",
    "        raise KeyError(f\"'{w}' not in vocabulary\")\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    a, b = np.asarray(a), np.asarray(b)\n",
    "    return float(np.dot(a, b) / (norm(a) * norm(b)))\n",
    "\n",
    "def norm_vec(x): \n",
    "    x = np.asarray(x)\n",
    "    return x / (norm(x) + 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6834da10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cosine similarity(probe, 'queen') = 0.8609578609466553\n",
       "[('queen', 0.8523604273796082), ('throne', 0.7664334177970886), ('prince', 0.759214460849762), ('daughter', 0.7473882436752319), ('elizabeth', 0.7460219860076904), ('princess', 0.7424570322036743), ('kingdom', 0.7337412238121033), ('monarch', 0.7214491367340088), ('eldest', 0.7184861898422241), ('widow', 0.7099431157112122)]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probe = v(\"king\") - v(\"man\") + v(\"woman\")\n",
    "sim_to_queen = cos_sim(probe, v(\"queen\"))\n",
    "# Nearest words to the probe:\n",
    "nearest = model.most_similar(positive=[\"king\",\"woman\"], negative=[\"man\"], topn=10)\n",
    "\n",
    "print(\"cosine similarity(probe, 'queen') =\", sim_to_queen)\n",
    "print(nearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0004d05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Top male-coded:\n",
       "ceo              0.275\n",
       "secretary        0.149\n",
       "assistant        0.131\n",
       "engineer         0.080\n",
       "programmer       0.066\n",
       "scientist        0.052\n",
       "\n",
       "Top female-coded:\n",
       "mechanic         0.004\n",
       "lawyer          -0.020\n",
       "teacher         -0.179\n",
       "librarian       -0.233\n",
       "receptionist    -0.331\n",
       "nurse           -0.380\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a gender axis\n",
    "g_axis = norm_vec(v(\"man\") - v(\"woman\"))\n",
    "\n",
    "def projection_on_gender(word):\n",
    "    vec = v(word)\n",
    "    return float(np.dot(norm_vec(vec), g_axis))\n",
    "\n",
    "occupations = [\n",
    "    \"engineer\",\"programmer\",\"ceo\",\"scientist\",\"lawyer\",\"mechanic\",\n",
    "    \"nurse\",\"receptionist\",\"teacher\",\"secretary\",\"librarian\",\"assistant\"\n",
    "]\n",
    "\n",
    "scores = [(w, projection_on_gender(w)) for w in occupations]\n",
    "scores_sorted = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Top male-coded:\")\n",
    "for w,s in scores_sorted[:6]:\n",
    "    print(f\"{w:15s} {s: .3f}\")\n",
    "print(\"\\nTop female-coded:\")\n",
    "for w,s in scores_sorted[-6:]:\n",
    "    print(f\"{w:15s} {s: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8cd935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SETUP: load word vectors and define helpers ---\n",
    "import gensim.downloader as api\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "from textwrap import fill\n",
    "\n",
    "# Load a small, fast model for demos (50d)\n",
    "model = api.load(\"glove-wiki-gigaword-50\")\n",
    "\n",
    "def cos_sim(a, b): \n",
    "    return 1 - distance.cosine(a, b)\n",
    "\n",
    "def cos_dist(a, b): \n",
    "    return distance.cosine(a, b)\n",
    "\n",
    "def explain(text, width=92):\n",
    "    print(fill(text, width=width))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cbd493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cosine distance(probe, 'queen') = 0.139  ->  similarity = 0.861\n",
       "\n",
       "Analogy test: take the direction from man→king and add it to woman. If the geometry encodes\n",
       "relational regularities, the result should land near 'queen'. A cosine distance of 0.139\n",
       "(similarity 0.861) indicates a strong association, showing the space composes relations\n",
       "rather than memorising pairs.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- ANALOGY DEMO ---\n",
    "probe = model[\"king\"] - model[\"man\"] + model[\"woman\"]\n",
    "sim = cos_sim(probe, model[\"queen\"])\n",
    "dist = cos_dist(probe, model[\"queen\"])\n",
    "\n",
    "print(f\"Cosine distance(probe, 'queen') = {dist:.3f}  ->  similarity = {sim:.3f}\\n\")\n",
    "explain(\n",
    "    \"Analogy test: take the direction from man→king and add it to woman. \"\n",
    "    \"If the geometry encodes relational regularities, the result should land near 'queen'. \"\n",
    "    f\"A cosine distance of {dist:.3f} (similarity {sim:.3f}) indicates a strong association, \"\n",
    "    \"showing the space composes relations rather than memorising pairs.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42abd56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Projection on the gender axis (man − woman):\n",
       "     assistant  +0.131\n",
       "      engineer  +0.080\n",
       "    programmer  +0.066\n",
       "     scientist  +0.052\n",
       "        lawyer  -0.020\n",
       "       teacher  -0.179\n",
       "  receptionist  -0.331\n",
       "         nurse  -0.380\n",
       "\n",
       "A single 'gender direction' is defined as the vector from 'woman' to 'man'. Projecting words\n",
       "on this axis quantifies corpus-coded gender alignment: positive values lean male-coded,\n",
       "negative values female-coded. This reflects aggregate regularities in the training data, not\n",
       "individual attitudes.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- GENDER AXIS + OCCUPATION PROJECTIONS ---\n",
    "gender_axis = (model[\"man\"] - model[\"woman\"])\n",
    "gender_axis = gender_axis / np.linalg.norm(gender_axis)\n",
    "\n",
    "occupations = [\"engineer\",\"scientist\",\"lawyer\",\"programmer\",\"nurse\",\"teacher\",\"assistant\",\"receptionist\"]\n",
    "\n",
    "rows = []\n",
    "for w in occupations:\n",
    "    if w in model:\n",
    "        v = model[w]\n",
    "        proj = np.dot(v/np.linalg.norm(v), gender_axis)\n",
    "        rows.append((w, proj))\n",
    "\n",
    "rows_sorted = sorted(rows, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Projection on the gender axis (man − woman):\")\n",
    "for w, p in rows_sorted:\n",
    "    print(f\"  {w:>12s}  {p:+.3f}\")\n",
    "print()\n",
    "\n",
    "explain(\n",
    "    \"A single 'gender direction' is defined as the vector from 'woman' to 'man'. \"\n",
    "    \"Projecting words on this axis quantifies corpus-coded gender alignment: positive values \"\n",
    "    \"lean male-coded, negative values female-coded. This reflects aggregate regularities in the \"\n",
    "    \"training data, not individual attitudes.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6698bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mini-WEAT effect size (science↔male vs arts↔female): 1.61\n",
       "\n",
       "A positive WEAT effect size means 'science' terms align more with male words than with\n",
       "female, and 'arts' terms align more with female than with male. This quantifies culturally\n",
       "patterned associations encoded in the distributional space.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- MINI WEAT (SCIENCE/ARTS × MALE/FEMALE) ---\n",
    "science = [\"science\",\"technology\",\"physics\",\"chemistry\",\"einstein\",\"nasa\",\"experiment\",\"astronomy\"]\n",
    "arts    = [\"poetry\",\"art\",\"dance\",\"literature\",\"novel\",\"symphony\",\"drama\",\"sculpture\"]\n",
    "male    = [\"man\",\"male\",\"boy\",\"brother\",\"he\",\"him\",\"his\",\"son\"]\n",
    "female  = [\"woman\",\"female\",\"girl\",\"sister\",\"she\",\"her\",\"hers\",\"daughter\"]\n",
    "\n",
    "def set_assoc(X, A, B):\n",
    "    # average similarity to set A minus average similarity to set B\n",
    "    simsA = [cos_sim(model[x], model[a]) for x in X for a in A if x in model and a in model]\n",
    "    simsB = [cos_sim(model[x], model[b]) for x in X for b in B if x in model and b in model]\n",
    "    return (np.mean(simsA) - np.mean(simsB))\n",
    "\n",
    "def weat_effect(X, Y, A, B):\n",
    "    sX = [set_assoc([x], A, B) for x in X if x in model]\n",
    "    sY = [set_assoc([y], A, B) for y in Y if y in model]\n",
    "    # pooled std\n",
    "    pooled = np.std(sX + sY, ddof=1)\n",
    "    return (np.mean(sX) - np.mean(sY)) / pooled if pooled > 0 else float(\"nan\")\n",
    "\n",
    "effect = weat_effect(science, arts, male, female)\n",
    "print(f\"Mini-WEAT effect size (science↔male vs arts↔female): {effect:.2f}\\n\")\n",
    "\n",
    "explain(\n",
    "    \"A positive WEAT effect size means 'science' terms align more with male words than with female, \"\n",
    "    \"and 'arts' terms align more with female than with male. This quantifies culturally patterned \"\n",
    "    \"associations encoded in the distributional space.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2de289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nearest neighbours of 'bank' (base): ['bank', 'banks', 'securities', 'banking', 'investment', 'exchange', 'financial', 'credit']\n",
       "Nearest neighbours of 'bank' (tilted toward finance): ['bank', 'banks', 'investment', 'credit', 'banking', 'financial', 'securities', 'funds']\n",
       "Nearest neighbours of 'bank' (tilted toward river): ['bank', 'banks', 'investment', 'credit', 'capital', 'banking', 'exchange', 'financial']\n",
       "\n",
       "Small directional tilts move 'bank' between financial and geographical neighbourhoods. This\n",
       "shows that meaning is not a single essence but a recombination of partial traces, assembled\n",
       "by context — an example of dividual sense composition.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- POLYSEMY DEMO: 'bank' as finance vs river ---\n",
    "targets = [\"bank\"]\n",
    "tilt_to_finance = (model[\"money\"] + model[\"loan\"] + model[\"finance\"]) / 3\n",
    "tilt_to_river   = (model[\"river\"] + model[\"stream\"] + model[\"water\"]) / 3\n",
    "\n",
    "def nearest(word_vec, k=8):\n",
    "    sims = []\n",
    "    for w in model.index_to_key[:50000]:  # cap for speed\n",
    "        sims.append((w, cos_sim(word_vec, model[w])))\n",
    "    sims.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [w for w,s in sims[:k]]\n",
    "\n",
    "base = model[\"bank\"]\n",
    "fin  = (base + 0.25*(tilt_to_finance - base))\n",
    "geo  = (base + 0.25*(tilt_to_river   - base))\n",
    "\n",
    "print(\"Nearest neighbours of 'bank' (base):\", nearest(base))\n",
    "print(\"Nearest neighbours of 'bank' (tilted toward finance):\", nearest(fin))\n",
    "print(\"Nearest neighbours of 'bank' (tilted toward river):\", nearest(geo))\n",
    "print()\n",
    "\n",
    "explain(\n",
    "    \"Small directional tilts move 'bank' between financial and geographical neighbourhoods. \"\n",
    "    \"This shows that meaning is not a single essence but a recombination of partial traces, \"\n",
    "    \"assembled by context — an example of dividual sense composition.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6613964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Projection before vs after neutralisation (man − woman axis):\n",
       "      engineer  +0.080  →  -0.000\n",
       "     scientist  +0.052  →  -0.000\n",
       "        lawyer  -0.020  →  +0.000\n",
       "         nurse  -0.380  →  +0.000\n",
       "       teacher  -0.179  →  +0.000\n",
       "  receptionist  -0.331  →  +0.000\n",
       "\n",
       "Neutralising vectors along the gender axis reduces alignment for many occupations. This is a\n",
       "concrete, model-internal intervention: a worked example of counter-sequencing, where we\n",
       "alter the sequencing through which the model routes meaning.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- COUNTER-SEQUENCING: NEUTRALISE GENDER COMPONENT ---\n",
    "def neutralise(v, axis):\n",
    "    axis = axis/np.linalg.norm(axis)\n",
    "    return v - np.dot(v, axis)*axis\n",
    "\n",
    "def proj(word):\n",
    "    v = model[word]\n",
    "    return np.dot(v/np.linalg.norm(v), gender_axis)\n",
    "\n",
    "probe_words = [\"engineer\",\"scientist\",\"lawyer\",\"nurse\",\"teacher\",\"receptionist\"]\n",
    "\n",
    "print(\"Projection before vs after neutralisation (man − woman axis):\")\n",
    "for w in probe_words:\n",
    "    if w in model:\n",
    "        before = proj(w)\n",
    "        after  = np.dot(neutralise(model[w], gender_axis)/np.linalg.norm(neutralise(model[w], gender_axis)), gender_axis)\n",
    "        print(f\"  {w:>12s}  {before:+.3f}  →  {after:+.3f}\")\n",
    "print()\n",
    "\n",
    "explain(\n",
    "    \"Neutralising vectors along the gender axis reduces alignment for many occupations. \"\n",
    "    \"This is a concrete, model-internal intervention: a worked example of counter-sequencing, \"\n",
    "    \"where we alter the sequencing through which the model routes meaning.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c960a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cos_sim(football, male)   = 0.297\n",
       "cos_sim(football, female) = 0.317\n",
       "\n",
       "In English news/web corpora, 'football' typically aligns more with 'male' than with\n",
       "'female'. This reflects co-occurrence patterns in the data, not intrinsic truths about the\n",
       "sport.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- SIMPLE INTUITIVE CHECK: 'football' with gender terms ---\n",
    "s_male   = cos_sim(model[\"football\"], model[\"male\"])\n",
    "s_female = cos_sim(model[\"football\"], model[\"female\"])\n",
    "print(f\"cos_sim(football, male)   = {s_male:.3f}\")\n",
    "print(f\"cos_sim(football, female) = {s_female:.3f}\\n\")\n",
    "\n",
    "explain(\n",
    "    \"In English news/web corpora, 'football' typically aligns more with 'male' than with 'female'. \"\n",
    "    \"This reflects co-occurrence patterns in the data, not intrinsic truths about the sport.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bebd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "How to read cosine measures: cosine similarity ranges from −1 to 1, where 1.0 means two\n",
       "vectors point in the same direction (very strong association), 0.0 means no directional\n",
       "association, and −1.0 means opposite directions. Some tools report cosine distance = 1 −\n",
       "cosine similarity; so a small distance (e.g., 0.14) implies a large similarity (0.86). As a\n",
       "rough guide, similarities ≥ 0.70 are often read as high, 0.40–0.69 as moderate, and ≤ 0.39\n",
       "as low, though thresholds vary by model.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- ONE-TIME PRIMER: HOW TO READ COSINE ---\n",
    "explain(\n",
    "    \"How to read cosine measures: cosine similarity ranges from −1 to 1, where 1.0 means two vectors \"\n",
    "    \"point in the same direction (very strong association), 0.0 means no directional association, and \"\n",
    "    \"−1.0 means opposite directions. Some tools report cosine distance = 1 − cosine similarity; \"\n",
    "    \"so a small distance (e.g., 0.14) implies a large similarity (0.86). As a rough guide, similarities \"\n",
    "    \"≥ 0.70 are often read as high, 0.40–0.69 as moderate, and ≤ 0.39 as low, though thresholds vary by model.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bf9841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
